{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Assignment 10: <br>\n",
    "### Student Name: Daniel Beckley\n",
    "### Student ID: 8846774"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment targets to assure that the students understood basic IR concepts.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Implementing an IR System (10/16)**<br>\n",
    "\n",
    "Consider a collection of 1000 documents and a set of 10 queries. Implement an IR system based on the Vector Space Model (VSM) using TF-IDF weighting.<br>\n",
    "\n",
    "Dataset:<br>\n",
    "\n",
    "- 1000 documents (text content for each document)\n",
    "- 10 sample queries <br>\n",
    "IR System:<br>\n",
    "\n",
    "Implement TF-IDF calculation for document-term matrix construction. <br>\n",
    "Develop a cosine similarity-based retrieval system to rank documents for each query. <br>\n",
    "Rank the top 10 documents for each query using the IR system. <br>\n",
    "Evaluation: <br>\n",
    "\n",
    "Compute Precision at k (P@k) for k=5, k=6, and k=10 for each query.<br>\n",
    "Calculate Mean Average Precision (MAP) across all queries. <br>\n",
    "Calculate the Mean Reciprocal Rank (MRR) across all queries.(3) <br><br>\n",
    "**Part 2: Assessing Inter-Annotator Agreement (6/16)**<br>\n",
    "\n",
    "Given the relevance assessments by three different annotators for a set of documents:<br>\n",
    "\n",
    "Annotator 1,2 and 3 relevance assessments<br>\n",
    "\n",
    "You are expected to: <br>\n",
    "\n",
    "Compute pairwise Cohen's Kappa values for the annotators' relevance assessments.<br>\n",
    "Discuss the observed agreement levels among annotators.<br>\n",
    "Explain how to improve the kappa value if we are not satisfied with the kappa.<br>\n",
    "Hint: Check Kappa Measure Last Slide Week 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------\n",
    "- Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"Machine learning is transforming various industries.\",\n",
    "    \"Natural language processing helps in text analysis.\",\n",
    "    \"AI algorithms can improve decision-making processes.\",\n",
    "    \"Data science involves extracting insights from data.\",\n",
    "    \"Robotics is a field combining hardware and software.\",\n",
    "    \"Deep learning models require large amounts of data.\",\n",
    "    \"Blockchain technology secures digital transactions.\",\n",
    "    \"Cloud computing offers scalable computing power.\",\n",
    "    \"Virtual reality provides immersive experiences.\",\n",
    "    \"Augmented reality enhances real-world environments.\",\n",
    "    \"Internet of Things connects devices for data exchange.\",\n",
    "    \"Biometric authentication ensures secure access.\",\n",
    "    \"Quantum computing promises faster computations.\",\n",
    "    \"Cybersecurity protects against digital threats.\",\n",
    "    \"Ethical considerations in AI development are crucial.\",\n",
    "    \"Healthcare benefits from AI-driven diagnostics.\",\n",
    "    \"E-commerce relies on personalized recommendation systems.\",\n",
    "    \"Autonomous vehicles revolutionize transportation.\",\n",
    "    \"Smart cities utilize IoT for efficient operations.\",\n",
    "    \"Social media analysis aids in understanding trends.\",\n",
    "    \"Predictive analytics anticipates future outcomes.\",\n",
    "    \"Remote work trends increase reliance on digital tools.\",\n",
    "    \"Energy efficiency through smart grids is vital.\",\n",
    "    \"Fintech innovations reshape financial services.\",\n",
    "    \"Data privacy concerns arise in the era of big data.\",\n",
    "    \"Artificial general intelligence remains a challenge.\",\n",
    "    \"Human-computer interaction shapes user experiences.\",\n",
    "    \"Big data analytics drives informed decision-making.\",\n",
    "    \"Climate change predictions benefit from AI models.\",\n",
    "    \"Bioinformatics applies computational techniques to biology.\",\n",
    "    \"Robotic process automation streamlines workflows.\",\n",
    "    \"Industry 4.0 integrates AI with manufacturing.\",\n",
    "    \"Sentiment analysis detects emotions in text data.\",\n",
    "    \"Reinforcement learning powers autonomous agents.\",\n",
    "    \"Data visualization simplifies complex information.\",\n",
    "    \"Edge computing reduces latency in data processing.\",\n",
    "    \"Smart farming optimizes agricultural practices.\",\n",
    "    \"AI in education enhances personalized learning.\",\n",
    "    \"Natural disaster predictions leverage machine learning.\",\n",
    "    \"Media recommendation systems personalize content.\",\n",
    "    \"Speech recognition enables hands-free interactions.\",\n",
    "    \"Genetic algorithms mimic natural selection.\",\n",
    "    \"Neural networks simulate the human brain.\",\n",
    "    \"Behavioral analytics uncovers patterns in behavior.\",\n",
    "    \"Spatial analysis benefits from geospatial data.\",\n",
    "    \"Explainable AI improves transparency in models.\",\n",
    "    \"AI ethics guide responsible technology development.\",\n",
    "    \"Prescriptive analytics offers actionable insights.\",\n",
    "    \"Supply chain optimization employs predictive models.\",\n",
    "    \"Emotion AI detects emotions in facial expressions.\",\n",
    "    \"Distributed ledger technology ensures secure transactions.\",\n",
    "    \"Biological data analysis aids in medical research.\",\n",
    "    \"Smart grid technology enhances energy distribution.\",\n",
    "    \"AI-powered chatbots automate customer support.\",\n",
    "    \"Machine translation breaks language barriers.\",\n",
    "    \"Personalized medicine tailors treatments to individuals.\",\n",
    "    \"Data-driven marketing optimizes customer engagement.\",\n",
    "    \"Smart home devices enhance living experiences.\",\n",
    "    \"Time series forecasting predicts future trends.\",\n",
    "    \"AI-driven creativity challenges human capabilities.\",\n",
    "    \"Intelligent document processing automates data extraction.\",\n",
    "    \"Graph analytics explores relationships in networks.\",\n",
    "    \"Adversarial attacks pose challenges to AI security.\",\n",
    "    \"Predictive maintenance minimizes equipment downtime.\",\n",
    "    \"Spatial reasoning enhances AI navigation systems.\",\n",
    "    \"Privacy-preserving techniques protect sensitive data.\",\n",
    "    \"Automated decision-making raises ethical concerns.\",\n",
    "    \"Behavioral biometrics verifies user identities.\",\n",
    "    \"Explainable recommendations increase user trust.\",\n",
    "    \"Quantum machine learning explores quantum states.\",\n",
    "    \"Internet censorship detection uses AI techniques.\",\n",
    "    \"Smart wearables monitor health and fitness.\",\n",
    "    \"Intelligent tutoring systems adapt to student needs.\",\n",
    "    \"Graph neural networks model complex relationships.\",\n",
    "    \"AI in sports analytics improves performance analysis.\",\n",
    "    \"Facial recognition technology raises privacy debates.\",\n",
    "    \"Digital twin technology replicates physical systems.\",\n",
    "    \"Emotion detection in video content aids analysis.\",\n",
    "    \"Neuromorphic computing mimics brain structure.\",\n",
    "    \"Robotic surgery enhances precision in operations.\",\n",
    "    \"AI-powered language translation assists global communication.\",\n",
    "    \"Automated content moderation filters online content.\",\n",
    "    \"Network anomaly detection identifies security threats.\",\n",
    "    \"Predictive policing uses data to prevent crime.\",\n",
    "    \"Quantum cryptography ensures secure communications.\",\n",
    "    \"AI-generated art challenges traditional creativity.\",\n",
    "    \"Ethical considerations in autonomous vehicles are debated.\",\n",
    "    \"Adaptive learning systems personalize educational content.\",\n",
    "    \"Biomedical image analysis aids in disease diagnosis.\",\n",
    "    \"Explainable computer vision interprets image features.\",\n",
    "    \"AI-driven personalization enhances user experiences.\",\n",
    "    \"Conversational AI improves human-like interactions.\",\n",
    "    \"Federated learning protects individual data privacy.\",\n",
    "    \"Human-centered AI design prioritizes user needs.\",\n",
    "    \"Quantum annealing solves optimization problems.\",\n",
    "    \"Behavior-based authentication enhances security.\",\n",
    "    \"AI in music composition transforms creative processes.\",\n",
    "    \"Semantic search improves information retrieval.\",\n",
    "    \"Recommender systems optimize user preferences.\",\n",
    "    \"Information Retrieval systems are outdated without neural networks\"\n",
    "]\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What are the impacts of AI on healthcare?\",\n",
    "    \"How does machine learning improve financial services?\",\n",
    "    \"What is the role of AI in autonomous vehicles?\",\n",
    "    \"Explain the applications of natural language processing.\",\n",
    "    \"How does robotics benefit from AI integration?\",\n",
    "    \"What are the challenges in implementing AI in education?\",\n",
    "    \"How does data science contribute to climate change predictions?\",\n",
    "    \"What are the ethical considerations in AI development?\",\n",
    "    \"Explain the significance of AI in smart cities.\",\n",
    "    \"How does AI enhance cybersecurity measures?\"\n",
    "]\n",
    "print(len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "ground_truth =[[3, 74, 38, 92, 71, 72, 98, 48, 18, 100], \n",
    "                [12, 26, 52, 54, 21, 63, 64, 45, 14, 83],\n",
    "                [58, 77, 62, 31, 6, 61, 36, 96, 85, 18], \n",
    "                [99, 62, 98, 34, 63, 79, 43, 31, 3, 16],\n",
    "                [8, 88, 73, 82, 37, 25, 34, 87, 66, 58], \n",
    "                [90, 40, 84, 64, 34, 2, 73, 23, 59, 89],\n",
    "                [80, 10, 86, 21, 68, 37, 83, 57, 6, 98],\n",
    "                [22, 3, 2, 44, 56, 80, 50, 63, 87, 13],\n",
    "                [1, 18, 22, 44, 99, 72, 24, 95, 10, 87],\n",
    "                [31, 10, 56, 50, 75, 4, 18, 85, 84, 74]\n",
    "                           ]\n",
    "print(len(ground_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Implement your solution for part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Machine', 'learning', 'is', 'transforming', 'various', 'industries', '.'],\n",
       " ['Natural', 'language', 'processing', 'helps', 'in', 'text', 'analysis', '.'],\n",
       " ['AI', 'algorithms', 'can', 'improve', 'decision-making', 'processes', '.'],\n",
       " ['Data',\n",
       "  'science',\n",
       "  'involves',\n",
       "  'extracting',\n",
       "  'insights',\n",
       "  'from',\n",
       "  'data',\n",
       "  '.'],\n",
       " ['Robotics',\n",
       "  'is',\n",
       "  'a',\n",
       "  'field',\n",
       "  'combining',\n",
       "  'hardware',\n",
       "  'and',\n",
       "  'software',\n",
       "  '.'],\n",
       " ['Deep',\n",
       "  'learning',\n",
       "  'models',\n",
       "  'require',\n",
       "  'large',\n",
       "  'amounts',\n",
       "  'of',\n",
       "  'data',\n",
       "  '.'],\n",
       " ['Blockchain', 'technology', 'secures', 'digital', 'transactions', '.'],\n",
       " ['Cloud', 'computing', 'offers', 'scalable', 'computing', 'power', '.'],\n",
       " ['Virtual', 'reality', 'provides', 'immersive', 'experiences', '.'],\n",
       " ['Augmented', 'reality', 'enhances', 'real-world', 'environments', '.'],\n",
       " ['Internet',\n",
       "  'of',\n",
       "  'Things',\n",
       "  'connects',\n",
       "  'devices',\n",
       "  'for',\n",
       "  'data',\n",
       "  'exchange',\n",
       "  '.'],\n",
       " ['Biometric', 'authentication', 'ensures', 'secure', 'access', '.'],\n",
       " ['Quantum', 'computing', 'promises', 'faster', 'computations', '.'],\n",
       " ['Cybersecurity', 'protects', 'against', 'digital', 'threats', '.'],\n",
       " ['Ethical',\n",
       "  'considerations',\n",
       "  'in',\n",
       "  'AI',\n",
       "  'development',\n",
       "  'are',\n",
       "  'crucial',\n",
       "  '.'],\n",
       " ['Healthcare', 'benefits', 'from', 'AI-driven', 'diagnostics', '.'],\n",
       " ['E-commerce',\n",
       "  'relies',\n",
       "  'on',\n",
       "  'personalized',\n",
       "  'recommendation',\n",
       "  'systems',\n",
       "  '.'],\n",
       " ['Autonomous', 'vehicles', 'revolutionize', 'transportation', '.'],\n",
       " ['Smart', 'cities', 'utilize', 'IoT', 'for', 'efficient', 'operations', '.'],\n",
       " ['Social', 'media', 'analysis', 'aids', 'in', 'understanding', 'trends', '.'],\n",
       " ['Predictive', 'analytics', 'anticipates', 'future', 'outcomes', '.'],\n",
       " ['Remote',\n",
       "  'work',\n",
       "  'trends',\n",
       "  'increase',\n",
       "  'reliance',\n",
       "  'on',\n",
       "  'digital',\n",
       "  'tools',\n",
       "  '.'],\n",
       " ['Energy', 'efficiency', 'through', 'smart', 'grids', 'is', 'vital', '.'],\n",
       " ['Fintech', 'innovations', 'reshape', 'financial', 'services', '.'],\n",
       " ['Data',\n",
       "  'privacy',\n",
       "  'concerns',\n",
       "  'arise',\n",
       "  'in',\n",
       "  'the',\n",
       "  'era',\n",
       "  'of',\n",
       "  'big',\n",
       "  'data',\n",
       "  '.'],\n",
       " ['Artificial', 'general', 'intelligence', 'remains', 'a', 'challenge', '.'],\n",
       " ['Human-computer', 'interaction', 'shapes', 'user', 'experiences', '.'],\n",
       " ['Big', 'data', 'analytics', 'drives', 'informed', 'decision-making', '.'],\n",
       " ['Climate', 'change', 'predictions', 'benefit', 'from', 'AI', 'models', '.'],\n",
       " ['Bioinformatics',\n",
       "  'applies',\n",
       "  'computational',\n",
       "  'techniques',\n",
       "  'to',\n",
       "  'biology',\n",
       "  '.'],\n",
       " ['Robotic', 'process', 'automation', 'streamlines', 'workflows', '.'],\n",
       " ['Industry', '4.0', 'integrates', 'AI', 'with', 'manufacturing', '.'],\n",
       " ['Sentiment', 'analysis', 'detects', 'emotions', 'in', 'text', 'data', '.'],\n",
       " ['Reinforcement', 'learning', 'powers', 'autonomous', 'agents', '.'],\n",
       " ['Data', 'visualization', 'simplifies', 'complex', 'information', '.'],\n",
       " ['Edge', 'computing', 'reduces', 'latency', 'in', 'data', 'processing', '.'],\n",
       " ['Smart', 'farming', 'optimizes', 'agricultural', 'practices', '.'],\n",
       " ['AI', 'in', 'education', 'enhances', 'personalized', 'learning', '.'],\n",
       " ['Natural',\n",
       "  'disaster',\n",
       "  'predictions',\n",
       "  'leverage',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  '.'],\n",
       " ['Media', 'recommendation', 'systems', 'personalize', 'content', '.'],\n",
       " ['Speech', 'recognition', 'enables', 'hands-free', 'interactions', '.'],\n",
       " ['Genetic', 'algorithms', 'mimic', 'natural', 'selection', '.'],\n",
       " ['Neural', 'networks', 'simulate', 'the', 'human', 'brain', '.'],\n",
       " ['Behavioral', 'analytics', 'uncovers', 'patterns', 'in', 'behavior', '.'],\n",
       " ['Spatial', 'analysis', 'benefits', 'from', 'geospatial', 'data', '.'],\n",
       " ['Explainable', 'AI', 'improves', 'transparency', 'in', 'models', '.'],\n",
       " ['AI', 'ethics', 'guide', 'responsible', 'technology', 'development', '.'],\n",
       " ['Prescriptive', 'analytics', 'offers', 'actionable', 'insights', '.'],\n",
       " ['Supply', 'chain', 'optimization', 'employs', 'predictive', 'models', '.'],\n",
       " ['Emotion', 'AI', 'detects', 'emotions', 'in', 'facial', 'expressions', '.'],\n",
       " ['Distributed',\n",
       "  'ledger',\n",
       "  'technology',\n",
       "  'ensures',\n",
       "  'secure',\n",
       "  'transactions',\n",
       "  '.'],\n",
       " ['Biological', 'data', 'analysis', 'aids', 'in', 'medical', 'research', '.'],\n",
       " ['Smart', 'grid', 'technology', 'enhances', 'energy', 'distribution', '.'],\n",
       " ['AI-powered', 'chatbots', 'automate', 'customer', 'support', '.'],\n",
       " ['Machine', 'translation', 'breaks', 'language', 'barriers', '.'],\n",
       " ['Personalized',\n",
       "  'medicine',\n",
       "  'tailors',\n",
       "  'treatments',\n",
       "  'to',\n",
       "  'individuals',\n",
       "  '.'],\n",
       " ['Data-driven', 'marketing', 'optimizes', 'customer', 'engagement', '.'],\n",
       " ['Smart', 'home', 'devices', 'enhance', 'living', 'experiences', '.'],\n",
       " ['Time', 'series', 'forecasting', 'predicts', 'future', 'trends', '.'],\n",
       " ['AI-driven', 'creativity', 'challenges', 'human', 'capabilities', '.'],\n",
       " ['Intelligent',\n",
       "  'document',\n",
       "  'processing',\n",
       "  'automates',\n",
       "  'data',\n",
       "  'extraction',\n",
       "  '.'],\n",
       " ['Graph', 'analytics', 'explores', 'relationships', 'in', 'networks', '.'],\n",
       " ['Adversarial', 'attacks', 'pose', 'challenges', 'to', 'AI', 'security', '.'],\n",
       " ['Predictive', 'maintenance', 'minimizes', 'equipment', 'downtime', '.'],\n",
       " ['Spatial', 'reasoning', 'enhances', 'AI', 'navigation', 'systems', '.'],\n",
       " ['Privacy-preserving', 'techniques', 'protect', 'sensitive', 'data', '.'],\n",
       " ['Automated', 'decision-making', 'raises', 'ethical', 'concerns', '.'],\n",
       " ['Behavioral', 'biometrics', 'verifies', 'user', 'identities', '.'],\n",
       " ['Explainable', 'recommendations', 'increase', 'user', 'trust', '.'],\n",
       " ['Quantum', 'machine', 'learning', 'explores', 'quantum', 'states', '.'],\n",
       " ['Internet', 'censorship', 'detection', 'uses', 'AI', 'techniques', '.'],\n",
       " ['Smart', 'wearables', 'monitor', 'health', 'and', 'fitness', '.'],\n",
       " ['Intelligent',\n",
       "  'tutoring',\n",
       "  'systems',\n",
       "  'adapt',\n",
       "  'to',\n",
       "  'student',\n",
       "  'needs',\n",
       "  '.'],\n",
       " ['Graph', 'neural', 'networks', 'model', 'complex', 'relationships', '.'],\n",
       " ['AI',\n",
       "  'in',\n",
       "  'sports',\n",
       "  'analytics',\n",
       "  'improves',\n",
       "  'performance',\n",
       "  'analysis',\n",
       "  '.'],\n",
       " ['Facial', 'recognition', 'technology', 'raises', 'privacy', 'debates', '.'],\n",
       " ['Digital', 'twin', 'technology', 'replicates', 'physical', 'systems', '.'],\n",
       " ['Emotion', 'detection', 'in', 'video', 'content', 'aids', 'analysis', '.'],\n",
       " ['Neuromorphic', 'computing', 'mimics', 'brain', 'structure', '.'],\n",
       " ['Robotic', 'surgery', 'enhances', 'precision', 'in', 'operations', '.'],\n",
       " ['AI-powered',\n",
       "  'language',\n",
       "  'translation',\n",
       "  'assists',\n",
       "  'global',\n",
       "  'communication',\n",
       "  '.'],\n",
       " ['Automated', 'content', 'moderation', 'filters', 'online', 'content', '.'],\n",
       " ['Network', 'anomaly', 'detection', 'identifies', 'security', 'threats', '.'],\n",
       " ['Predictive', 'policing', 'uses', 'data', 'to', 'prevent', 'crime', '.'],\n",
       " ['Quantum', 'cryptography', 'ensures', 'secure', 'communications', '.'],\n",
       " ['AI-generated', 'art', 'challenges', 'traditional', 'creativity', '.'],\n",
       " ['Ethical',\n",
       "  'considerations',\n",
       "  'in',\n",
       "  'autonomous',\n",
       "  'vehicles',\n",
       "  'are',\n",
       "  'debated',\n",
       "  '.'],\n",
       " ['Adaptive',\n",
       "  'learning',\n",
       "  'systems',\n",
       "  'personalize',\n",
       "  'educational',\n",
       "  'content',\n",
       "  '.'],\n",
       " ['Biomedical',\n",
       "  'image',\n",
       "  'analysis',\n",
       "  'aids',\n",
       "  'in',\n",
       "  'disease',\n",
       "  'diagnosis',\n",
       "  '.'],\n",
       " ['Explainable', 'computer', 'vision', 'interprets', 'image', 'features', '.'],\n",
       " ['AI-driven', 'personalization', 'enhances', 'user', 'experiences', '.'],\n",
       " ['Conversational', 'AI', 'improves', 'human-like', 'interactions', '.'],\n",
       " ['Federated', 'learning', 'protects', 'individual', 'data', 'privacy', '.'],\n",
       " ['Human-centered', 'AI', 'design', 'prioritizes', 'user', 'needs', '.'],\n",
       " ['Quantum', 'annealing', 'solves', 'optimization', 'problems', '.'],\n",
       " ['Behavior-based', 'authentication', 'enhances', 'security', '.'],\n",
       " ['AI',\n",
       "  'in',\n",
       "  'music',\n",
       "  'composition',\n",
       "  'transforms',\n",
       "  'creative',\n",
       "  'processes',\n",
       "  '.'],\n",
       " ['Semantic', 'search', 'improves', 'information', 'retrieval', '.'],\n",
       " ['Recommender', 'systems', 'optimize', 'user', 'preferences', '.'],\n",
       " ['Information',\n",
       "  'Retrieval',\n",
       "  'systems',\n",
       "  'are',\n",
       "  'outdated',\n",
       "  'without',\n",
       "  'neural',\n",
       "  'networks']]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_documents = [word_tokenize(document) for document in documents]\n",
    "tokenized_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['machine', 'learning', 'transforming', 'various', 'industries', '.'],\n",
       " ['natural', 'language', 'processing', 'helps', 'text', 'analysis', '.'],\n",
       " ['ai', 'algorithms', 'improve', 'decision-making', 'processes', '.'],\n",
       " ['data', 'science', 'involves', 'extracting', 'insights', 'data', '.'],\n",
       " ['robotics', 'field', 'combining', 'hardware', 'software', '.'],\n",
       " ['deep', 'learning', 'models', 'require', 'large', 'amounts', 'data', '.'],\n",
       " ['blockchain', 'technology', 'secures', 'digital', 'transactions', '.'],\n",
       " ['cloud', 'computing', 'offers', 'scalable', 'computing', 'power', '.'],\n",
       " ['virtual', 'reality', 'provides', 'immersive', 'experiences', '.'],\n",
       " ['augmented', 'reality', 'enhances', 'real-world', 'environments', '.'],\n",
       " ['internet', 'things', 'connects', 'devices', 'data', 'exchange', '.'],\n",
       " ['biometric', 'authentication', 'ensures', 'secure', 'access', '.'],\n",
       " ['quantum', 'computing', 'promises', 'faster', 'computations', '.'],\n",
       " ['cybersecurity', 'protects', 'digital', 'threats', '.'],\n",
       " ['ethical', 'considerations', 'ai', 'development', 'crucial', '.'],\n",
       " ['healthcare', 'benefits', 'ai-driven', 'diagnostics', '.'],\n",
       " ['e-commerce', 'relies', 'personalized', 'recommendation', 'systems', '.'],\n",
       " ['autonomous', 'vehicles', 'revolutionize', 'transportation', '.'],\n",
       " ['smart', 'cities', 'utilize', 'iot', 'efficient', 'operations', '.'],\n",
       " ['social', 'media', 'analysis', 'aids', 'understanding', 'trends', '.'],\n",
       " ['predictive', 'analytics', 'anticipates', 'future', 'outcomes', '.'],\n",
       " ['remote', 'work', 'trends', 'increase', 'reliance', 'digital', 'tools', '.'],\n",
       " ['energy', 'efficiency', 'smart', 'grids', 'vital', '.'],\n",
       " ['fintech', 'innovations', 'reshape', 'financial', 'services', '.'],\n",
       " ['data', 'privacy', 'concerns', 'arise', 'era', 'big', 'data', '.'],\n",
       " ['artificial', 'general', 'intelligence', 'remains', 'challenge', '.'],\n",
       " ['human-computer', 'interaction', 'shapes', 'user', 'experiences', '.'],\n",
       " ['big', 'data', 'analytics', 'drives', 'informed', 'decision-making', '.'],\n",
       " ['climate', 'change', 'predictions', 'benefit', 'ai', 'models', '.'],\n",
       " ['bioinformatics', 'applies', 'computational', 'techniques', 'biology', '.'],\n",
       " ['robotic', 'process', 'automation', 'streamlines', 'workflows', '.'],\n",
       " ['industry', '4.0', 'integrates', 'ai', 'manufacturing', '.'],\n",
       " ['sentiment', 'analysis', 'detects', 'emotions', 'text', 'data', '.'],\n",
       " ['reinforcement', 'learning', 'powers', 'autonomous', 'agents', '.'],\n",
       " ['data', 'visualization', 'simplifies', 'complex', 'information', '.'],\n",
       " ['edge', 'computing', 'reduces', 'latency', 'data', 'processing', '.'],\n",
       " ['smart', 'farming', 'optimizes', 'agricultural', 'practices', '.'],\n",
       " ['ai', 'education', 'enhances', 'personalized', 'learning', '.'],\n",
       " ['natural',\n",
       "  'disaster',\n",
       "  'predictions',\n",
       "  'leverage',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  '.'],\n",
       " ['media', 'recommendation', 'systems', 'personalize', 'content', '.'],\n",
       " ['speech', 'recognition', 'enables', 'hands-free', 'interactions', '.'],\n",
       " ['genetic', 'algorithms', 'mimic', 'natural', 'selection', '.'],\n",
       " ['neural', 'networks', 'simulate', 'human', 'brain', '.'],\n",
       " ['behavioral', 'analytics', 'uncovers', 'patterns', 'behavior', '.'],\n",
       " ['spatial', 'analysis', 'benefits', 'geospatial', 'data', '.'],\n",
       " ['explainable', 'ai', 'improves', 'transparency', 'models', '.'],\n",
       " ['ai', 'ethics', 'guide', 'responsible', 'technology', 'development', '.'],\n",
       " ['prescriptive', 'analytics', 'offers', 'actionable', 'insights', '.'],\n",
       " ['supply', 'chain', 'optimization', 'employs', 'predictive', 'models', '.'],\n",
       " ['emotion', 'ai', 'detects', 'emotions', 'facial', 'expressions', '.'],\n",
       " ['distributed',\n",
       "  'ledger',\n",
       "  'technology',\n",
       "  'ensures',\n",
       "  'secure',\n",
       "  'transactions',\n",
       "  '.'],\n",
       " ['biological', 'data', 'analysis', 'aids', 'medical', 'research', '.'],\n",
       " ['smart', 'grid', 'technology', 'enhances', 'energy', 'distribution', '.'],\n",
       " ['ai-powered', 'chatbots', 'automate', 'customer', 'support', '.'],\n",
       " ['machine', 'translation', 'breaks', 'language', 'barriers', '.'],\n",
       " ['personalized', 'medicine', 'tailors', 'treatments', 'individuals', '.'],\n",
       " ['data-driven', 'marketing', 'optimizes', 'customer', 'engagement', '.'],\n",
       " ['smart', 'home', 'devices', 'enhance', 'living', 'experiences', '.'],\n",
       " ['time', 'series', 'forecasting', 'predicts', 'future', 'trends', '.'],\n",
       " ['ai-driven', 'creativity', 'challenges', 'human', 'capabilities', '.'],\n",
       " ['intelligent',\n",
       "  'document',\n",
       "  'processing',\n",
       "  'automates',\n",
       "  'data',\n",
       "  'extraction',\n",
       "  '.'],\n",
       " ['graph', 'analytics', 'explores', 'relationships', 'networks', '.'],\n",
       " ['adversarial', 'attacks', 'pose', 'challenges', 'ai', 'security', '.'],\n",
       " ['predictive', 'maintenance', 'minimizes', 'equipment', 'downtime', '.'],\n",
       " ['spatial', 'reasoning', 'enhances', 'ai', 'navigation', 'systems', '.'],\n",
       " ['privacy-preserving', 'techniques', 'protect', 'sensitive', 'data', '.'],\n",
       " ['automated', 'decision-making', 'raises', 'ethical', 'concerns', '.'],\n",
       " ['behavioral', 'biometrics', 'verifies', 'user', 'identities', '.'],\n",
       " ['explainable', 'recommendations', 'increase', 'user', 'trust', '.'],\n",
       " ['quantum', 'machine', 'learning', 'explores', 'quantum', 'states', '.'],\n",
       " ['internet', 'censorship', 'detection', 'uses', 'ai', 'techniques', '.'],\n",
       " ['smart', 'wearables', 'monitor', 'health', 'fitness', '.'],\n",
       " ['intelligent', 'tutoring', 'systems', 'adapt', 'student', 'needs', '.'],\n",
       " ['graph', 'neural', 'networks', 'model', 'complex', 'relationships', '.'],\n",
       " ['ai', 'sports', 'analytics', 'improves', 'performance', 'analysis', '.'],\n",
       " ['facial', 'recognition', 'technology', 'raises', 'privacy', 'debates', '.'],\n",
       " ['digital', 'twin', 'technology', 'replicates', 'physical', 'systems', '.'],\n",
       " ['emotion', 'detection', 'video', 'content', 'aids', 'analysis', '.'],\n",
       " ['neuromorphic', 'computing', 'mimics', 'brain', 'structure', '.'],\n",
       " ['robotic', 'surgery', 'enhances', 'precision', 'operations', '.'],\n",
       " ['ai-powered',\n",
       "  'language',\n",
       "  'translation',\n",
       "  'assists',\n",
       "  'global',\n",
       "  'communication',\n",
       "  '.'],\n",
       " ['automated', 'content', 'moderation', 'filters', 'online', 'content', '.'],\n",
       " ['network', 'anomaly', 'detection', 'identifies', 'security', 'threats', '.'],\n",
       " ['predictive', 'policing', 'uses', 'data', 'prevent', 'crime', '.'],\n",
       " ['quantum', 'cryptography', 'ensures', 'secure', 'communications', '.'],\n",
       " ['ai-generated', 'art', 'challenges', 'traditional', 'creativity', '.'],\n",
       " ['ethical', 'considerations', 'autonomous', 'vehicles', 'debated', '.'],\n",
       " ['adaptive',\n",
       "  'learning',\n",
       "  'systems',\n",
       "  'personalize',\n",
       "  'educational',\n",
       "  'content',\n",
       "  '.'],\n",
       " ['biomedical', 'image', 'analysis', 'aids', 'disease', 'diagnosis', '.'],\n",
       " ['explainable', 'computer', 'vision', 'interprets', 'image', 'features', '.'],\n",
       " ['ai-driven', 'personalization', 'enhances', 'user', 'experiences', '.'],\n",
       " ['conversational', 'ai', 'improves', 'human-like', 'interactions', '.'],\n",
       " ['federated', 'learning', 'protects', 'individual', 'data', 'privacy', '.'],\n",
       " ['human-centered', 'ai', 'design', 'prioritizes', 'user', 'needs', '.'],\n",
       " ['quantum', 'annealing', 'solves', 'optimization', 'problems', '.'],\n",
       " ['behavior-based', 'authentication', 'enhances', 'security', '.'],\n",
       " ['ai', 'music', 'composition', 'transforms', 'creative', 'processes', '.'],\n",
       " ['semantic', 'search', 'improves', 'information', 'retrieval', '.'],\n",
       " ['recommender', 'systems', 'optimize', 'user', 'preferences', '.'],\n",
       " ['information',\n",
       "  'retrieval',\n",
       "  'systems',\n",
       "  'outdated',\n",
       "  'without',\n",
       "  'neural',\n",
       "  'networks']]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "cleaned_data = [[word.lower() for word in document if word.lower() not in english_stopwords] for document in tokenized_documents]\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine learning transforming various industries .',\n",
       " 'natural language processing helps text analysis .',\n",
       " 'ai algorithms improve decision-making processes .',\n",
       " 'data science involves extracting insights data .',\n",
       " 'robotics field combining hardware software .',\n",
       " 'deep learning models require large amounts data .',\n",
       " 'blockchain technology secures digital transactions .',\n",
       " 'cloud computing offers scalable computing power .',\n",
       " 'virtual reality provides immersive experiences .',\n",
       " 'augmented reality enhances real-world environments .',\n",
       " 'internet things connects devices data exchange .',\n",
       " 'biometric authentication ensures secure access .',\n",
       " 'quantum computing promises faster computations .',\n",
       " 'cybersecurity protects digital threats .',\n",
       " 'ethical considerations ai development crucial .',\n",
       " 'healthcare benefits ai-driven diagnostics .',\n",
       " 'e-commerce relies personalized recommendation systems .',\n",
       " 'autonomous vehicles revolutionize transportation .',\n",
       " 'smart cities utilize iot efficient operations .',\n",
       " 'social media analysis aids understanding trends .',\n",
       " 'predictive analytics anticipates future outcomes .',\n",
       " 'remote work trends increase reliance digital tools .',\n",
       " 'energy efficiency smart grids vital .',\n",
       " 'fintech innovations reshape financial services .',\n",
       " 'data privacy concerns arise era big data .',\n",
       " 'artificial general intelligence remains challenge .',\n",
       " 'human-computer interaction shapes user experiences .',\n",
       " 'big data analytics drives informed decision-making .',\n",
       " 'climate change predictions benefit ai models .',\n",
       " 'bioinformatics applies computational techniques biology .',\n",
       " 'robotic process automation streamlines workflows .',\n",
       " 'industry 4.0 integrates ai manufacturing .',\n",
       " 'sentiment analysis detects emotions text data .',\n",
       " 'reinforcement learning powers autonomous agents .',\n",
       " 'data visualization simplifies complex information .',\n",
       " 'edge computing reduces latency data processing .',\n",
       " 'smart farming optimizes agricultural practices .',\n",
       " 'ai education enhances personalized learning .',\n",
       " 'natural disaster predictions leverage machine learning .',\n",
       " 'media recommendation systems personalize content .',\n",
       " 'speech recognition enables hands-free interactions .',\n",
       " 'genetic algorithms mimic natural selection .',\n",
       " 'neural networks simulate human brain .',\n",
       " 'behavioral analytics uncovers patterns behavior .',\n",
       " 'spatial analysis benefits geospatial data .',\n",
       " 'explainable ai improves transparency models .',\n",
       " 'ai ethics guide responsible technology development .',\n",
       " 'prescriptive analytics offers actionable insights .',\n",
       " 'supply chain optimization employs predictive models .',\n",
       " 'emotion ai detects emotions facial expressions .',\n",
       " 'distributed ledger technology ensures secure transactions .',\n",
       " 'biological data analysis aids medical research .',\n",
       " 'smart grid technology enhances energy distribution .',\n",
       " 'ai-powered chatbots automate customer support .',\n",
       " 'machine translation breaks language barriers .',\n",
       " 'personalized medicine tailors treatments individuals .',\n",
       " 'data-driven marketing optimizes customer engagement .',\n",
       " 'smart home devices enhance living experiences .',\n",
       " 'time series forecasting predicts future trends .',\n",
       " 'ai-driven creativity challenges human capabilities .',\n",
       " 'intelligent document processing automates data extraction .',\n",
       " 'graph analytics explores relationships networks .',\n",
       " 'adversarial attacks pose challenges ai security .',\n",
       " 'predictive maintenance minimizes equipment downtime .',\n",
       " 'spatial reasoning enhances ai navigation systems .',\n",
       " 'privacy-preserving techniques protect sensitive data .',\n",
       " 'automated decision-making raises ethical concerns .',\n",
       " 'behavioral biometrics verifies user identities .',\n",
       " 'explainable recommendations increase user trust .',\n",
       " 'quantum machine learning explores quantum states .',\n",
       " 'internet censorship detection uses ai techniques .',\n",
       " 'smart wearables monitor health fitness .',\n",
       " 'intelligent tutoring systems adapt student needs .',\n",
       " 'graph neural networks model complex relationships .',\n",
       " 'ai sports analytics improves performance analysis .',\n",
       " 'facial recognition technology raises privacy debates .',\n",
       " 'digital twin technology replicates physical systems .',\n",
       " 'emotion detection video content aids analysis .',\n",
       " 'neuromorphic computing mimics brain structure .',\n",
       " 'robotic surgery enhances precision operations .',\n",
       " 'ai-powered language translation assists global communication .',\n",
       " 'automated content moderation filters online content .',\n",
       " 'network anomaly detection identifies security threats .',\n",
       " 'predictive policing uses data prevent crime .',\n",
       " 'quantum cryptography ensures secure communications .',\n",
       " 'ai-generated art challenges traditional creativity .',\n",
       " 'ethical considerations autonomous vehicles debated .',\n",
       " 'adaptive learning systems personalize educational content .',\n",
       " 'biomedical image analysis aids disease diagnosis .',\n",
       " 'explainable computer vision interprets image features .',\n",
       " 'ai-driven personalization enhances user experiences .',\n",
       " 'conversational ai improves human-like interactions .',\n",
       " 'federated learning protects individual data privacy .',\n",
       " 'human-centered ai design prioritizes user needs .',\n",
       " 'quantum annealing solves optimization problems .',\n",
       " 'behavior-based authentication enhances security .',\n",
       " 'ai music composition transforms creative processes .',\n",
       " 'semantic search improves information retrieval .',\n",
       " 'recommender systems optimize user preferences .',\n",
       " 'information retrieval systems outdated without neural networks']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences = [' '.join(document) for document in cleaned_data]\n",
    "cleaned_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 163)\t0.49120372384880856\n",
      "  (0, 327)\t0.49120372384880856\n",
      "  (0, 312)\t0.49120372384880856\n",
      "  (0, 181)\t0.34109961564339564\n",
      "  (0, 186)\t0.3997596243233148\n",
      "  (1, 11)\t0.3259493911700577\n",
      "  (1, 305)\t0.43071911294080617\n",
      "  (1, 151)\t0.4693864999729862\n",
      "  (1, 242)\t0.4032841652344177\n",
      "  (1, 178)\t0.4032841652344177\n",
      "  (1, 202)\t0.4032841652344177\n",
      "  (2, 241)\t0.43630037870457955\n",
      "  (2, 188)\t0.4085099284682032\n",
      "  (2, 81)\t0.4085099284682032\n",
      "  (2, 158)\t0.47546881841107386\n",
      "  (2, 9)\t0.43630037870457955\n",
      "  (2, 7)\t0.24382911739385216\n",
      "  (3, 168)\t0.40332998980704693\n",
      "  (3, 123)\t0.4395385451021021\n",
      "  (3, 176)\t0.4395385451021021\n",
      "  (3, 273)\t0.4395385451021021\n",
      "  (3, 78)\t0.5076834854816823\n",
      "  (4, 289)\t0.4472135954999579\n",
      "  (4, 148)\t0.4472135954999579\n",
      "  (4, 56)\t0.4472135954999579\n",
      "  :\t:\n",
      "  (95, 23)\t0.4623932891322133\n",
      "  (95, 111)\t0.3619774719865355\n",
      "  (96, 71)\t0.4425900318406722\n",
      "  (96, 313)\t0.4425900318406722\n",
      "  (96, 61)\t0.4425900318406722\n",
      "  (96, 201)\t0.4425900318406722\n",
      "  (96, 241)\t0.40613009944220513\n",
      "  (96, 7)\t0.2269682735277233\n",
      "  (97, 268)\t0.4455030793792585\n",
      "  (97, 274)\t0.4854976825366838\n",
      "  (97, 279)\t0.4854976825366838\n",
      "  (97, 159)\t0.39511583841421116\n",
      "  (97, 165)\t0.4171264568459447\n",
      "  (98, 233)\t0.4976450584487141\n",
      "  (98, 213)\t0.4976450584487141\n",
      "  (98, 255)\t0.4976450584487141\n",
      "  (98, 324)\t0.37098218197927724\n",
      "  (98, 301)\t0.34557258001557645\n",
      "  (99, 336)\t0.4278457597149894\n",
      "  (99, 216)\t0.4278457597149894\n",
      "  (99, 268)\t0.39260043931926286\n",
      "  (99, 206)\t0.34819658701250344\n",
      "  (99, 207)\t0.3675934865311952\n",
      "  (99, 165)\t0.3675934865311952\n",
      "  (99, 301)\t0.29710284573974216\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(cleaned_sentences)\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Query (similar to documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    query_tokens = word_tokenize(query)\n",
    "    query_cleaned = [word.lower() for word in query_tokens if word.lower() not in english_stopwords]\n",
    "    query_cleaned_combined = ' '.join(query_cleaned)\n",
    "    return query_cleaned_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Cosine SImilarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documents are indexed from 1 to 100 for this presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_top_10_similar_docs(query, tfidf_matrix):\n",
    "    # Preprocess the query\n",
    "    query_cleaned = preprocess_query(query)\n",
    "\n",
    "    # Transform the query into a TF-IDF vector\n",
    "    query_tfidf = tfidf_vectorizer.transform([query_cleaned])\n",
    "\n",
    "    # Calculate the cosine similarity between the query vector and all document vectors\n",
    "    cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix)\n",
    "\n",
    "    # Get the indices of the 10 most similar documents\n",
    "\n",
    "    top_indices = np.argsort(cosine_similarities, axis=1)[0, -10:][::-1]\n",
    "    \n",
    "    # Adjust indices to start from 1 instead of 0\n",
    "    top_indices_adjusted = top_indices + 1\n",
    "\n",
    "    return top_indices_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([16, 38, 32, 46, 91, 15, 75, 65, 60, 92], dtype=int64),\n",
       " array([24,  1, 39, 70,  3, 55, 38, 34, 93, 88], dtype=int64),\n",
       " array([18, 87, 34, 38, 32, 46, 91, 15, 16, 75], dtype=int64),\n",
       " array([ 2, 55, 42, 39, 36, 61, 81, 28, 29, 30], dtype=int64),\n",
       " array([29,  5, 38, 32, 46, 91, 15, 16, 75, 65], dtype=int64),\n",
       " array([38, 60, 63, 86, 32, 46, 91, 15, 16, 75], dtype=int64),\n",
       " array([29,  4, 39, 25, 45, 35, 93, 33, 52, 57], dtype=int64),\n",
       " array([15, 87, 47, 67, 38, 32, 46, 91, 16, 75], dtype=int64),\n",
       " array([19, 37, 23, 53, 72, 58, 38, 32, 46, 91], dtype=int64),\n",
       " array([14, 58, 38, 32, 46, 91, 15, 16, 75, 65], dtype=int64)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_similar_docs = [get_top_10_similar_docs(query, tfidf_matrix) for query in queries]\n",
    "top_10_similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision at K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ground_truth, retrieved_docs, k=10):\n",
    "    precisions = []\n",
    "    for i in range(len(ground_truth)):\n",
    "        correct_predictions = set(ground_truth[i])\n",
    "        \n",
    "        top_k_predictions = set(retrieved_docs[i][:k])\n",
    "        \n",
    "        precision = len(correct_predictions.intersection(top_k_predictions)) / k\n",
    "        \n",
    "        precisions.append(precision)\n",
    "    return precisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision at k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(ground_truth, top_10_similar_docs, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision at k = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16666666666666666,\n",
       " 0.0,\n",
       " 0.16666666666666666,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.16666666666666666,\n",
       " 0.16666666666666666,\n",
       " 0.0]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(ground_truth, top_10_similar_docs, k=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision at k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.0, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(ground_truth, top_10_similar_docs, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_average_precision(retrieved_documents, relevant_documents):\n",
    "    # Find the indices (k values) where retrieved documents are relevant\n",
    "    k_values_ap = [i + 1 for i in range(len(retrieved_documents)) if retrieved_documents[i] in relevant_documents]\n",
    "    # print(f'Indices of relevant and retrieved documents are: {k_values_ap}')\n",
    "\n",
    "    # Calculate Precision at k for each relevant and retrieved document\n",
    "    precision_k_lists_ap = []\n",
    "    for k in k_values_ap:\n",
    "        # Retrieve the top k documents\n",
    "        retrieved_k_documents = retrieved_documents[:k]\n",
    "        # Calculate the number of True Positives (relevant documents in the top k)\n",
    "        TP_k = len(set(relevant_documents) & set(retrieved_k_documents))\n",
    "        # Calculate Precision at k\n",
    "        precision_k = TP_k / len(retrieved_k_documents)\n",
    "        precision_k_lists_ap.append(precision_k)\n",
    "\n",
    "    # print(precision_k_lists_ap)\n",
    "\n",
    "    # If precision_k_lists_ap is empty, set average_precision to 0, otherwise calculate the mean\n",
    "    if not precision_k_lists_ap:  # Check if the list is empty\n",
    "        average_precision = 0\n",
    "    else:\n",
    "        average_precision = np.nanmean(precision_k_lists_ap) * 100  # Use nanmean to handle NaN values\n",
    "\n",
    "    # print(f'Average Precision is {average_precision}%')\n",
    "\n",
    "    return average_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_average_precision(top_10_similar_docs[0], ground_truth[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.0, 0, 100.0, 0, 0, 0, 10.0, 50.0, 20.0, 11.11111111111111]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precisions = [calculate_average_precision(retrieved_docs, relevant_docs) for retrieved_docs, relevant_docs in zip(top_10_similar_docs, ground_truth)]\n",
    "average_precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_map(ap_scores):\n",
    "\n",
    "    map_score = np.mean(ap_scores)\n",
    "\n",
    "    print(f'Mean Average Precision (MAP) is: {map_score}%')\n",
    "\n",
    "    return map_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision (MAP) is: 22.61111111111111%\n"
     ]
    }
   ],
   "source": [
    "map_score = calculate_map(average_precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Reciprocal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(list_of_retrieved_documents, list_of_relevant_documents):\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for retrieved_docs, relevant_docs in zip(list_of_retrieved_documents, list_of_relevant_documents):\n",
    "        rr = 0\n",
    "        for rank, doc in enumerate(retrieved_docs, start=1):\n",
    "            if doc in relevant_docs:\n",
    "                rr = 1 / rank\n",
    "                break\n",
    "        reciprocal_ranks.append(rr)\n",
    "\n",
    "    mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "    print(f'Mean Reciprocal Rank (MRR) is: {mrr}')\n",
    "\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR) is: 0.24111111111111114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24111111111111114"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mrr(top_10_similar_docs, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "## - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is not relevant, 1 is relevant\n",
    "annotator1_relevance = [1, 0, 1, 0, 1, 1, 0, 0, 1, 0]  \n",
    "annotator2_relevance = [1, 1, 1, 0, 1, 0, 0, 1, 1, 1]  \n",
    "annotator3_relevance = [1, 0, 0, 0, 1, 0, 0, 1, 1, 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Implement your solution for part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Cohen's Kappa Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_kappa_score(annotator1, annotator2):\n",
    "    confusion_matrix_res = confusion_matrix(annotator2, annotator1)\n",
    "    total_docs = len(annotator1)\n",
    "    \n",
    "    # Calculate the probability of agreeing\n",
    "    prob_agreeing = (confusion_matrix_res[0, 0] + confusion_matrix_res[1, 1]) / total_docs\n",
    "    \n",
    "    # Calculate the probability of both annotators marking a document as relevant by chance\n",
    "    prob_relevant = (sum(confusion_matrix_res[:, 1]) / total_docs) * (sum(confusion_matrix_res[1, :]) / total_docs)\n",
    "    \n",
    "    # Calculate the probability of both annotators marking a document as not relevant by chance\n",
    "    prob_not_relevant = (sum(confusion_matrix_res[:, 0]) / total_docs) * (sum(confusion_matrix_res[0, :]) / total_docs)\n",
    "    \n",
    "    # Calculate the total probability of chance agreement\n",
    "    prob_chance = prob_relevant + prob_not_relevant\n",
    "    \n",
    "    # Calculate kappa score\n",
    "    kappa_score = (prob_agreeing - prob_chance) / (1 - prob_chance)\n",
    "    \n",
    "    return kappa_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19999999999999996"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa_score_1 = calculate_kappa_score(annotator1_relevance, annotator2_relevance)\n",
    "kappa_score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3999999999999999"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa_score_2 = calculate_kappa_score(annotator1_relevance, annotator3_relevance)\n",
    "kappa_score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa_score_3 = calculate_kappa_score(annotator2_relevance, annotator3_relevance)\n",
    "kappa_score_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For annotator 1 and annotator 2, a kappa score of 0.2 shows a slight agreement beyond what would be expected by chance alone on the relevance assessments. The low kappa value suggests that these two annotators have relatively divergent views on what constitutes relevance in the context of their assessments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For annotator 1 and annotator 3, a kappa score of 0.4 shows a fair agreement suggesting that annotator 1 and annotator 3 have more similar criteria or interpretations for relevance, leading to more consistent judgments compared to the first pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For annotator 2 and annotator 3, a kappa score of 0.44 shows a moderate agreement, slightly higher than the agreement between annotator 1 and annotator 3. It suggests that annotator 2 and annotator 3 share relatively similar assessment criteria, resulting in a slightly more consistent judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Improve Kappa Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More annotators are needed or replace one of the annotators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the guidelines for making relevance assessments are clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct training sessions where annotators can practice making assessments and receive feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider whether the task itself may be too subjective or if the categories are too broad or overlapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Pairwise Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3481481481481481"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_pairwise_kappa = (kappa_score_1 + kappa_score_2 + kappa_score_3) / 3\n",
    "average_pairwise_kappa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "cscn8010_classic_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
